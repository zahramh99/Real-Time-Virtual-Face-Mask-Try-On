name: "FaceMask_Detection_TryOn_Network"

# Input configuration (300x300 RGB)
input: "data"
input_shape {
  dim: 1  # Batch size
  dim: 3  # Channels (RGB)
  dim: 300  # Height
  dim: 300  # Width
}

# ----------------- Initial Preprocessing -----------------
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

# ----------------- Initial Convolution -----------------
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  convolution_param {
    num_output: 32
    kernel_size: 7
    stride: 2
    pad: 3
    weight_filler { type: "msra" variance_norm: FAN_OUT }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param { bias_term: true }
}

layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}

# ----------------- Residual Block 1 (64 channels) -----------------
layer {
  name: "res1_1_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "res1_1_conv1"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res1_1_bn"
  type: "BatchNorm"
  bottom: "res1_1_conv1"
  top: "res1_1_conv1"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res1_1_relu"
  type: "ReLU"
  bottom: "res1_1_conv1"
  top: "res1_1_conv1"
}

layer {
  name: "res1_1_conv2"
  type: "Convolution"
  bottom: "res1_1_conv1"
  top: "res1_1_conv2"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res1_1_sum"
  type: "Eltwise"
  bottom: "res1_1_conv2"
  bottom: "pool1"
  top: "res1_sum"
}

# ----------------- Residual Block 2 (128 channels) -----------------
layer {
  name: "res2_1_bn"
  type: "BatchNorm"
  bottom: "res1_sum"
  top: "res2_1_bn"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res2_1_scale"
  type: "Scale"
  bottom: "res2_1_bn"
  top: "res2_1_bn"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "res2_1_relu"
  type: "ReLU"
  bottom: "res2_1_bn"
  top: "res2_1_bn"
}

layer {
  name: "res2_1_conv1"
  type: "Convolution"
  bottom: "res2_1_bn"
  top: "res2_1_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 2
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res2_1_bn2"
  type: "BatchNorm"
  bottom: "res2_1_conv1"
  top: "res2_1_conv1"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res2_1_scale2"
  type: "Scale"
  bottom: "res2_1_conv1"
  top: "res2_1_conv1"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "res2_1_relu2"
  type: "ReLU"
  bottom: "res2_1_conv1"
  top: "res2_1_conv1"
}

layer {
  name: "res2_1_conv2"
  type: "Convolution"
  bottom: "res2_1_conv1"
  top: "res2_1_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res2_1_conv_expand"
  type: "Convolution"
  bottom: "res2_1_bn"
  top: "res2_1_conv_expand"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 2
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res2_1_sum"
  type: "Eltwise"
  bottom: "res2_1_conv2"
  bottom: "res2_1_conv_expand"
  top: "res2_sum"
}

# ----------------- Residual Block 3 (256 channels) -----------------
layer {
  name: "res3_1_bn"
  type: "BatchNorm"
  bottom: "res2_sum"
  top: "res3_1_bn"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res3_1_scale"
  type: "Scale"
  bottom: "res3_1_bn"
  top: "res3_1_bn"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "res3_1_relu"
  type: "ReLU"
  bottom: "res3_1_bn"
  top: "res3_1_bn"
}

layer {
  name: "res3_1_conv1"
  type: "Convolution"
  bottom: "res3_1_bn"
  top: "res3_1_conv1"
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 2
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res3_1_bn2"
  type: "BatchNorm"
  bottom: "res3_1_conv1"
  top: "res3_1_conv1"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res3_1_scale2"
  type: "Scale"
  bottom: "res3_1_conv1"
  top: "res3_1_conv1"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "res3_1_relu2"
  type: "ReLU"
  bottom: "res3_1_conv1"
  top: "res3_1_conv1"
}

layer {
  name: "res3_1_conv2"
  type: "Convolution"
  bottom: "res3_1_conv1"
  top: "res3_1_conv2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res3_1_conv_expand"
  type: "Convolution"
  bottom: "res3_1_bn"
  top: "res3_1_conv_expand"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 2
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res3_1_sum"
  type: "Eltwise"
  bottom: "res3_1_conv2"
  bottom: "res3_1_conv_expand"
  top: "res3_sum"
}

# ----------------- Residual Block 4 (512 channels) -----------------
layer {
  name: "res4_1_bn"
  type: "BatchNorm"
  bottom: "res3_sum"
  top: "res4_1_bn"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res4_1_scale"
  type: "Scale"
  bottom: "res4_1_bn"
  top: "res4_1_bn"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "res4_1_relu"
  type: "ReLU"
  bottom: "res4_1_bn"
  top: "res4_1_bn"
}

layer {
  name: "res4_1_conv1"
  type: "Convolution"
  bottom: "res4_1_bn"
  top: "res4_1_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res4_1_bn2"
  type: "BatchNorm"
  bottom: "res4_1_conv1"
  top: "res4_1_conv1"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "res4_1_scale2"
  type: "Scale"
  bottom: "res4_1_conv1"
  top: "res4_1_conv1"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "res4_1_relu2"
  type: "ReLU"
  bottom: "res4_1_conv1"
  top: "res4_1_conv1"
}

layer {
  name: "res4_1_conv2"
  type: "Convolution"
  bottom: "res4_1_conv1"
  top: "res4_1_conv2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res4_1_conv_expand"
  type: "Convolution"
  bottom: "res4_1_bn"
  top: "res4_1_conv_expand"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    bias_term: false
    weight_filler { type: "msra" }
  }
}

layer {
  name: "res4_1_sum"
  type: "Eltwise"
  bottom: "res4_1_conv2"
  bottom: "res4_1_conv_expand"
  top: "res4_sum"
}

layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "res4_sum"
  top: "res4_sum"
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
  param { lr_mult: 0 decay_mult: 0 }
}

layer {
  name: "last_scale"
  type: "Scale"
  bottom: "res4_sum"
  top: "res4_sum"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }
  scale_param { bias_term: true }
}

layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "res4_sum"
  top: "fc7"
}

# ----------------- SSD Detection Layers -----------------
# conv4_3 (from res3) for detecting small faces
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "res3_sum"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler { type: "constant" value: 20 }
    channel_shared: false
  }
}

layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  convolution_param {
    num_output: 16  # 4 boxes * 4 coords
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  convolution_param {
    num_output: 8  # 4 boxes * 2 classes
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30.0
    max_size: 60.0
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}

# fc7 (from res4) for medium faces
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  convolution_param {
    num_output: 24  # 6 boxes * 4 coords
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  convolution_param {
    num_output: 12  # 6 boxes * 2 classes
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60.0
    max_size: 111.0
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}

# Additional detection layers (conv6_2 -> conv9_2)
# ... [Include all remaining detection layers from original]
# Example for one of them:
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2_h"
  top: "conv6_2_mbox_loc"
  convolution_param {
    num_output: 24
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}

# ----------------- Output Processing -----------------
# Concatenate all predictions
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param { axis: 1 }
}

layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param { axis: 1 }
}

layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param { axis: 2 }
}

# Softmax for classification
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param { shape { dim: 0 dim: -1 dim: 2 } }
}

layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param { axis: 2 }
}

layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param { axis: 1 }
}

# Final detection output
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include { phase: TEST }
  detection_output_param {
    num_classes: 2
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.25
  }
}